#!/usr/bin/env python

DESCRIPTION = 'Update git repositories from remotes.'
__doc__ = DESCRIPTION

import argparse
import concurrent.futures
import fnmatch
import logging
import logging.config
import os

import git

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': ('[%(levelname)8s %(asctime)s %(name)s %(thread)X] %(message)s'),
            'datefmt': '%Y-%m-%d %H:%M:%S',
        },
    },
    'handlers': {
        'console': {
            'level': 'DEBUG',
            'formatter': 'verbose',
            'class': 'logging.StreamHandler',
        },
    },
    'loggers': {
        'update-repos': {
            'handlers': ['console'],
            'level': 'WARNING',
            'propagate': False,
        },
    },
}

logging.config.dictConfig(LOGGING_CONFIG)
logger = logging.getLogger('update-repos')


def no_traceback_log_filter(record):
    '''log filter function to unconditionally remove exception info'''
    record.exc_info = None
    return True


class MyExecutor(concurrent.futures.ThreadPoolExecutor):
    '''A subclass of `ThreadPoolExecutor` that keeps track of all futures it
    creates, and provides access to them via a generator method'''

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._futures = []

    def submit(self, *args, **kwargs):
        ftr = super().submit(*args, **kwargs)
        self._futures.append(ftr)
        return ftr

    def futures(self):
        yield from self._futures


def depthwalk(top, maxdepth=0, **kwargs):
    '''just like `os.walk`, but with new added `maxdepth` parameter!'''
    depthmap = {top: 0}
    for path, dirs, files in os.walk(top, **kwargs):
        yield path, dirs, files
        here = depthmap[path]
        if here >= maxdepth:
            dirs.clear()
            continue
        for dir in dirs:
            child = os.path.join(path, dir)
            depthmap[child] = here + 1


def find_git_repos(root, maxdepth=None, exclude=None):
    '''find git repositories beneath a root directory, optionally limiting
    max depth. (will not return submodules)'''

    logger.info('finding git repositories: %s (maxdepth=%s)', root, maxdepth)

    root = os.path.realpath(root)

    if maxdepth is None:
        walk_generator = os.walk(root)
    else:
        walk_generator = depthwalk(root, maxdepth)

    if not exclude:
        exclude = []

    # possibilities for an exclusion pattern:
    # a single directory component (".git")
    # a partial path (".git/config")
    # a full relative path ("./workspace/mmicro")
    # ... an absolute path? ("/opt/dev/core.git")

    # i think this boils down to being either a path or a path fragment
    # i think we can detect paths by checking if a pattern starts with any
    # of "./", "../", or "/", ... or if it exactly matches "." or ".."

    # i think we should convert our roots and our paths all to canonical
    # absolute paths in order to compare them

    new_exclude = []
    for pattern in exclude:
        if pattern in ['.', '..']:
            pattern = pattern + '/'
        if any(pattern.startswith(prefix) for prefix in ('./', '../', '/')):
            new_exclude.append(os.path.realpath(pattern))
        else:
            new_exclude.append('*/' + pattern)

    repos = []

    for path, dirs, files in walk_generator:
        if '.git' in dirs:
            repos.append(path)
            # clearing `dirs` prevents `os.walk` from traversing any deeper
            dirs.clear()

        long_short_map = {os.path.join(path, dir): dir for dir in dirs}

        for pattern in new_exclude:
            for match in fnmatch.filter(long_short_map.keys(), pattern):
                dirs.remove(long_short_map[match])

    return repos


def update_regular_tracking_branch(repo, branch):
    '''update a local branch to match its remote tracking branch. may not be
    the currently checked out branch.'''


    tracking_branch = branch.tracking_branch()
    if tracking_branch is None:
        raise ValueError(f'Failed to update branch; no tracking branch: {repo.working_dir}, {branch}')

    local = branch.name
    upstream = tracking_branch.remote_head
    remote = repo.remotes[tracking_branch.remote_name]

    refspec = f'{upstream}:{local}'

    logger.debug('fetching: %s, %s, %s', repo.working_dir, remote, refspec)
    remote.fetch(refspec)


def update_current_tracking_branch(repo):
    '''update the currently checked out branch to match its remote tracking
    branch.'''

    branch = repo.head.ref
    tracking_branch = branch.tracking_branch()
    if tracking_branch is None:
        raise ValueError('Failed to pull; no tracking branch: {repo.working_dir}, {branch}')

    remote = repo.remotes[tracking_branch.remote_name]

    logger.debug('pulling: %s, %s, %s', repo.working_dir, remote, branch)
    remote.pull()
    repo.submodule_update()


def update_branch(repo, branch):
    '''if a branch has a remote tracking branch, update it.'''

    if not branch.tracking_branch():
        logger.log(5, 'branch has no remote tracking branch: %s, %s', repo.working_dir, branch)
    elif (not repo.head.is_detached) and repo.head.ref == branch:
        update_current_tracking_branch(repo)
    else:
        update_regular_tracking_branch(repo, branch)


def update_repo(path):
    failures = False
    logger.info('Updating: %s', path)
    try:
        repo = git.Repo(path)
    except Exception:
        logger.exception('Failed to initialize repository: %s', path)
        failures = True
    else:
        for remote in repo.remotes:
            logger.debug('fetching: %s, %s', repo.working_dir, remote)
            try:
                remote.fetch()
            except Exception:
                logger.exception('Failed to fetch: %s, %s', repo.working_dir, remote)
                failures = True

        for branch in repo.branches:
            try:
                update_branch(repo, branch)
            except Exception:
                logger.exception('Failed to update branch: %s, %s', repo.working_dir, branch)
                failures = True

    return failures


def parse_arguments():
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument('directories', nargs='*', default=['.'],
                        help='directories to search for repositories (defaults to current directory)')
    parser.add_argument('-d', '--depth', type=int, help='maximum depth to search for repositories')
    parser.add_argument('-e', '--exclude', action='append',
                        help=('directories to exclude from consideration; may be repeated; accepts wildcards '
                             '(remember to quote them!)'))
    parser.add_argument('-1','--single-thread', action='store_true',
                        help='Run in a single thread. useful for background tasks, or debugging.')

    # action_group = parser.add_mutually_exclusive_group()
    # action_group.add_argument('-u', '--update', action='store_true',
    #                           help='update repositories (the default)')
    # action_group.add_argument('-s', '--status', action='store_true',
    #                           help='report the status of located repositories')

    parser.add_argument('-p', '--print', action='store_true',
                        help="don't update; print the paths of located repositories")

    volume_group = parser.add_mutually_exclusive_group()
    volume_group.add_argument('-v', '--verbose', action='count', default=0,
                              help='increase the verbosity of the script (can be specified up to twice)')
    volume_group.add_argument('-q', '--quiet', action='store_true',
                              help='silence all output (cannot be combined with --verbose)')

    traceback_group = parser.add_mutually_exclusive_group()
    traceback_group.add_argument('-t', '--traceback', action='store_true',
                                 help='display tracebacks on error (defaults to True when verbose >= 2)')
    traceback_group.add_argument('--no-traceback', action='store_true',
                                 help='disable tracebacks (even when verbose >= 2)')


    args = parser.parse_args()

    # the `no_traceback_log_filter` logic is intentionally long-winded
    # in order to be more readable

    # disable traceback by default
    logger.addFilter(no_traceback_log_filter)

    if args.traceback:
        logger.removeFilter(no_traceback_log_filter)

    if args.quiet:
        logger.level = logging.FATAL
    elif args.verbose >= 2:
        logger.level = logging.DEBUG
        # re-enable tracebacks when verbose => 2
        logger.removeFilter(no_traceback_log_filter)
        # unless `--no-traceback` is specified
        if args.no_traceback:
            logger.addFilter(no_traceback_log_filter)
    elif args.verbose >= 1:
        logger.level = logging.INFO

    return args


def _main_singlethreaded(args):
    failures = False

    for directory in args.directories:
        # `repos` here are just strings, not yet `git.Repo` objects
        repos = find_git_repos(directory, maxdepth=args.depth, exclude=args.exclude)

        if args.print:
            for repo in repos:
                print(repo)
        else:
            for repo in repos:
                try:
                    failures |= update_repo(repo)
                except Exception as exc:
                    logger.exception('Trapped error: %s', exc)
                    failures = True

    return failures


def _main_multithreaded(args):
    executor = MyExecutor(os.cpu_count())
    failures = False

    for directory in args.directories:
        # `repos` here are just strings, not yet `git.Repo` objects
        repos = find_git_repos(directory, maxdepth=args.depth, exclude=args.exclude)

        for repo in repos:
            executor.submit(update_repo, repo)

    try:
        for ftr in concurrent.futures.as_completed(executor.futures()):
            try:
                failures |= ftr.result()
            except Exception as exc:
                logger.exception('Trapped error: %s', exc)
                failures = True
    except KeyboardInterrupt:
        for ftr in executor.futures():
            ftr.cancel()
    finally:
        executor.shutdown()

    return failures


def main():
    __doc__ = DESCRIPTION

    args = parse_arguments()

    os.environ['GIT_ASKPASS'] = 'echo'

    try:
        if args.single_thread or args.print:
            failures = _main_singlethreaded(args)
        else:
            failures = _main_multithreaded(args)
    except KeyboardInterrupt:
        print('Caught interrupt')
        exit(0)

    exit(failures)

if __name__ == '__main__':
    main()
